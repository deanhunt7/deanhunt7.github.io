Name five areas where deep learning is now the best in the world.
1. Cardiology - better at identifying images than trained cardiologists.
2. Games - chess, go, strategy games
3. Facial recognition
4. Sound recognition
5. Image classification

What was the name of the first device that was based on the principle of the artificial neuron?
This was called the perceptron.

Based on the book of the same name, what are the requirements for parallel distributed processing (PDP)?
You need processing units, which have a state of activation, with an ouput function and pattern of connectivity, a propogation rule, an activation rule, a learning rule in an environment.

What were the two theoretical misunderstandings that held back the field of neural networks?
1. They thought that since the single layer couldn't do well at some problems, there was no point continuing with the deep learning structure.
2. Even with two layers, the model was generally too large and slow. They needed even more layers.

Why is it hard to use a traditional computer program to recognize images in a photo?
You need to program every little detail that makes that thing unique.

What did Samuel mean by "weight assignment"?
Assigning parameters for each iteration of learning.

What term do we normally use in deep learning for what Samuel called "weights"?
Parameters.

Draw a picture that summarizes Samuel's view of a machine learning model.
Why is it hard to understand why a deep learning model makes a particular prediction?
What is the name of the theorem that shows that a neural network can solve any mathematical problem to any level of accuracy?
UAT: Universal Approximation Theorem

https://towardsdatascience.com/can-neural-networks-really-learn-any-function-65e106617fc6#:~:text=The%20Universal%20Approximation%20Theorem%20states,be%20able%20to%20approximate%20it.
This link helped me understand the theorem, and understand why it has to be within a given range (I liken it to overfitting; if you train it on a certain range, the function, unless linear, won't follow the same pattern for another range.)

http://neuralnetworksanddeeplearning.com
This site was awesome. I got the fundamental idea of sigmoid neurons from it, as opposed to step-function perceptrons. Sigmoid curves look like a little S, and essentially give more grey area for a single neuron. This allows the neuron to add up more nuanced weights and make more granular decisions from this.


What is the difference between classification and regression?
Prediction vs Classification, basically.
